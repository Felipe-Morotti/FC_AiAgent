{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b438e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: groq in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (0.24.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (2.11.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install groq\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05fa3737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "664d910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GROQ_API_KEY'] = \"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\"\n",
    "\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbbc1c7",
   "metadata": {},
   "source": [
    "### Download colocado acima para diminuir tempo de execução do código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96a26fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294c3418",
   "metadata": {},
   "source": [
    "### Classe Agent gerencia a interação com o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1fd48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, client: Groq, system: str = \"\") -> None:\n",
    "        self.client = client\n",
    "        self.system = system\n",
    "        self.messages: list = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message=\"\"):\n",
    "        # Mantém histórico limitado (últimas 10 mensagens)\n",
    "        if len(self.messages) > 10:\n",
    "            self.messages = [self.messages[0]] + self.messages[-9:]\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        try:\n",
    "            # Chamada à API com tratamento de erros\n",
    "            completion = self.client.chat.completions.create(\n",
    "                model=\"llama3-70b-8192\",\n",
    "                messages=self.messages\n",
    "            )\n",
    "            if not completion.choices:\n",
    "                raise ValueError(\"Resposta vazia da API\")\n",
    "            return completion.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"Erro na API: {e}\")\n",
    "            return f\"Erro: {e}\"\n",
    "    \n",
    "    def reset(self):\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": self.system})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90860e1b",
   "metadata": {},
   "source": [
    "### Função de análise linguística usando NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73b333b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_words(frase):\n",
    "    # Tokenização e tagging gramatical\n",
    "    tokens = word_tokenize(frase) # Separa a frase em palavras\n",
    "    tags = pos_tag(tokens) # Classifica gramaticalmente cada palavra\n",
    "    return str(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923d3800",
   "metadata": {},
   "source": [
    "### Sistema principal de classificação de frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fa42d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifie_sentence(sentence):\n",
    "    # Define um prompt estruturado no formato ReAct\n",
    "    system_prompt = \"\"\"\n",
    "    You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "    At the end of the loop you output an Answer.\n",
    "    Use Thought to describe your thoughts about the question you have been asked.\n",
    "    Use Action to run one of the actions available to you - then return PAUSE.\n",
    "    Observation will be the result of running those actions.\n",
    "\n",
    "    Your available actions are:\n",
    "    class_words:\n",
    "    e.g. class_words(frase)\n",
    "    returns a list with the words and their grammatical class\n",
    "\n",
    "    Example session:\n",
    "    Frase: The black cat jumped over the tall brick wall.\n",
    "    Thought: I need to analyze the grammatical structure of this sentence.\n",
    "    Action: class_words(The black cat jumped over the tall brick wall)\n",
    "    PAUSE\n",
    "\n",
    "    Observation: [('The', 'DT'), ('black', 'JJ'), ('cat', 'NN'), ('jumped', 'VBD'), ('over', 'IN'), ('the', 'DT'), ('tall', 'JJ'), ('brick', 'NN'), ('wall', 'NN')]\n",
    "\n",
    "    Answer: Here are the grammatical classifications:\n",
    "    [('The', 'DT'), ('black', 'JJ'), ('cat', 'NN'), ('jumped', 'VBD'), ('over', 'IN'), ('the', 'DT'), ('tall', 'JJ'), ('brick', 'NN'), ('wall', 'NN')]\n",
    "    \"\"\".strip()\n",
    "\n",
    "    GrammarAgent = Agent(client, system_prompt)\n",
    "    response = GrammarAgent(f\"Analyze this sentence: {sentence}\")\n",
    "    GrammarAgent.reset()\n",
    "\n",
    "    # Loop principal de interação\n",
    "    while True:\n",
    "        if \"PAUSE\" in response:\n",
    "            # Extrai e executa ações dinamicamente\n",
    "            action_line = next((line for line in response.split('\\n') if line.startswith(\"Action:\")), None)\n",
    "            if action_line:\n",
    "                action = action_line.split(\"Action:\")[1].strip()\n",
    "                if action.startswith(\"class_words(\"):\n",
    "                    # Executa a análise linguística\n",
    "                    frase = action[len(\"class_words(\"):-1].strip()\n",
    "                    if not frase: \n",
    "                        frase = sentence\n",
    "                    observation = class_words(frase)\n",
    "                    response = GrammarAgent(f\"Observation: {observation}\")\n",
    "                else:\n",
    "                    response = GrammarAgent(\"Observation: Unknown action\")\n",
    "            else:\n",
    "                response = GrammarAgent(\"Observation: No action specified\")\n",
    "        \n",
    "        elif \"Answer:\" in response:\n",
    "            # Finaliza quando obtém uma resposta completa\n",
    "            return response.split(\"Answer:\")[1].strip()\n",
    "        \n",
    "        else:\n",
    "            response = GrammarAgent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3ba250",
   "metadata": {},
   "source": [
    "### Exemplo de uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a98de566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis result for 'The black cat jumps over the tall brick wall, falling on a dog.':\n",
      "Here are the grammatical classifications: [('The', 'DT), ('black', 'JJ'), ('cat', 'NN'), ('jumps', 'NNS'), ('over', 'IN'), ('the', 'DT'), ('tall', 'JJ'), ('brick', 'NN'), ('wall', 'NN'), (',', ','), ('falling', 'VBG'), ('on', 'IN'), ('a', 'DT'), ('dog', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_sentence = \"The black cat jumps over the tall brick wall, falling on a dog.\"\n",
    "    result = classifie_sentence(input_sentence)\n",
    "    print(f\"Analysis result for '{input_sentence}':\")\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
