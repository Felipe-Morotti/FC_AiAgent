{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3acf3334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: groq in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (0.24.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (2.11.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be40165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GROQ_API_KEY'] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e1675b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in the field of natural language processing (NLP) and have numerous applications in various industries. Here are some key importance of fast language models:\n",
      "\n",
      "1. **Efficient Processing**: Fast language models can process large amounts of text data quickly, making them ideal for applications where speed is essential, such as real-time language translation, sentiment analysis, and text summarization.\n",
      "2. **Improved User Experience**: Fast language models enable applications to respond quickly to user input, providing a seamless and interactive experience. This is particularly important for applications like chatbots, virtual assistants, and language translation apps.\n",
      "3. **Increased Productivity**: Fast language models can automate tasks like text classification, entity recognition, and language translation, freeing up time for humans to focus on more complex and high-value tasks.\n",
      "4. **Enhanced Accuracy**: Fast language models can be trained on large datasets, which improves their accuracy and ability to generalize to new, unseen data. This is particularly important for applications like language translation, sentiment analysis, and text classification.\n",
      "5. **Real-Time Insights**: Fast language models can analyze large amounts of text data in real-time, providing valuable insights and trends that can inform business decisions, marketing strategies, and customer service.\n",
      "6. **Competitive Advantage**: Organizations that adopt fast language models can gain a competitive advantage by providing faster and more accurate language processing capabilities, which can lead to improved customer satisfaction, increased revenue, and market share.\n",
      "7. **Scalability**: Fast language models can handle large volumes of text data, making them ideal for applications that require processing vast amounts of data, such as social media monitoring, customer feedback analysis, and news article processing.\n",
      "8. **Multilingual Support**: Fast language models can support multiple languages, enabling applications to cater to diverse user bases and expanding their reach globally.\n",
      "9. **Improved Customer Service**: Fast language models can power chatbots and virtual assistants that provide quick and accurate responses to customer inquiries, improving customer satisfaction and reducing support costs.\n",
      "10. **Research and Development**: Fast language models can accelerate research and development in areas like NLP, machine learning, and artificial intelligence, enabling researchers to explore new ideas and applications more efficiently.\n",
      "\n",
      "Some examples of applications that rely on fast language models include:\n",
      "\n",
      "* Virtual assistants like Siri, Alexa, and Google Assistant\n",
      "* Language translation apps like Google Translate and Microsoft Translator\n",
      "* Chatbots and customer service platforms\n",
      "* Sentiment analysis and opinion mining tools\n",
      "* Text summarization and news aggregation platforms\n",
      "* Social media monitoring and analytics tools\n",
      "\n",
      "In summary, fast language models are essential for building efficient, accurate, and scalable NLP applications that can provide real-time insights, improve user experience, and drive business value.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ed2a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, client: Groq, system: str = \"\") -> None:\n",
    "        self.client = client\n",
    "        self.system = system\n",
    "        self.messages: list = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message=\"\"):\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama3-70b-8192\", messages=self.messages\n",
    "        )\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dc4f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "get_planet_mass:\n",
    "e.g. get_planet_mass: Earth\n",
    "returns weight of the planet in kg\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the mass of Earth times 2?\n",
    "Thought: I need to find the mass of Earth\n",
    "Action: get_planet_mass: Earth\n",
    "PAUSE \n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: 5.972e24\n",
    "\n",
    "Thought: I need to multiply this by 2\n",
    "Action: calculate: 5.972e24 * 2\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this: \n",
    "\n",
    "Observation: 1,1944×10e25\n",
    "\n",
    "If you have the answer, output it as the Answer.\n",
    "\n",
    "Answer: The mass of Earth times 2 is 1,1944×10e25.\n",
    "\n",
    "Now it's your turn:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23655f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(operation: str) -> float:\n",
    "    return eval(operation)\n",
    "\n",
    "\n",
    "def get_planet_mass(planet) -> float:\n",
    "    match planet.lower():\n",
    "        case \"earth\":\n",
    "            return 5.972e24\n",
    "        case \"jupiter\":\n",
    "            return 1.898e27\n",
    "        case \"mars\":\n",
    "            return 6.39e23\n",
    "        case \"mercury\":\n",
    "            return 3.285e23\n",
    "        case \"neptune\":\n",
    "            return 1.024e26\n",
    "        case \"saturn\":\n",
    "            return 5.683e26\n",
    "        case \"uranus\":\n",
    "            return 8.681e25\n",
    "        case \"venus\":\n",
    "            return 4.867e24\n",
    "        case _:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07831e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "neil_tyson = Agent(client=client, system=system_prompt)\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def loop(max_iterations=10, query: str = \"\"):\n",
    "\n",
    "    agent = Agent(client=client, system=system_prompt)\n",
    "\n",
    "    tools = [\"calculate\", \"get_planet_mass\"]\n",
    "\n",
    "    next_prompt = query\n",
    "\n",
    "    i = 0\n",
    "  \n",
    "    while i < max_iterations:\n",
    "        i += 1\n",
    "        result = agent(next_prompt)\n",
    "        print(result)\n",
    "\n",
    "        if \"PAUSE\" in result and \"Action\" in result:\n",
    "            action = re.findall(r\"Action: ([a-z_]+): (.+)\", result, re.IGNORECASE)\n",
    "            chosen_tool = action[0][0]\n",
    "            arg = action[0][1]\n",
    "\n",
    "            if chosen_tool in tools:\n",
    "                result_tool = eval(f\"{chosen_tool}('{arg}')\")\n",
    "                next_prompt = f\"Observation: {result_tool}\"\n",
    "\n",
    "            else:\n",
    "                next_prompt = \"Observation: Tool not found\"\n",
    "\n",
    "            print(next_prompt)\n",
    "            continue\n",
    "\n",
    "        if \"Answer\" in result:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6bada9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to find the mass of Earth and Saturn, then add them and multiply by 2\n",
      "Thought: I need to find the mass of Earth and Saturn, then add them and multiply by 2\n",
      "Action: get_planet_mass: Earth \n",
      "PAUSE\n",
      "Observation: 0.0\n",
      "Thought: That's not right, let me try again to get the mass of Earth\n",
      "Action: get_planet_mass: Earth\n",
      "PAUSE\n",
      "Observation: 5.972e+24\n",
      "Thought: Now I have the mass of Earth, I need to find the mass of Saturn\n",
      "Action: get_planet_mass: Saturn\n",
      "PAUSE\n",
      "Observation: 5.683e+26\n",
      "Thought: Now I have the masses of both planets, I need to add them together\n",
      "Action: calculate: 5.972e24 + 5.683e26\n",
      "PAUSE\n",
      "Observation: 5.74272e+26\n",
      "Thought: Now I have the sum of the masses, I need to multiply it by 2\n",
      "Action: calculate: 5.74272e26 * 2\n",
      "PAUSE\n",
      "Observation: 1.148544e+27\n",
      "Thought: I've got my final answer!\n",
      "Answer: The mass of Earth plus the mass of Saturn and all of that times 2 is 1.148544e+27.\n"
     ]
    }
   ],
   "source": [
    "loop(query=\"What is the mass of Earth plus the mass of Saturn and all of that times 2?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
