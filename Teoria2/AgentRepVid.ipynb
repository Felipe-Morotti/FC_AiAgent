{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3acf3334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: groq in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (0.24.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (2.11.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be40165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GROQ_API_KEY'] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4bd89b",
   "metadata": {},
   "source": [
    "### Configuração inicial do cliente Groq para acessar a API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e1675b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in today's technological landscape, and their importance can be understood from several perspectives:\n",
      "\n",
      "1. **Efficient Processing**: Fast language models can process and generate human-like text at a much quicker pace than slower models. This is essential for applications where speed is critical, such as real-time chatbots, virtual assistants, and language translation services.\n",
      "2. **Improved User Experience**: Faster language models enable more responsive and interactive systems, leading to a better user experience. For instance, a fast language model can quickly respond to user queries, provide instant feedback, and engage in more natural-sounding conversations.\n",
      "3. **Scalability and Deployment**: Fast language models can be deployed on a larger scale, handling a higher volume of requests and users without sacrificing performance. This makes them ideal for applications with a large user base, such as social media platforms, online forums, and customer service portals.\n",
      "4. **Reduced Computational Resources**: Fast language models typically require less computational power and memory to operate, which reduces the overall cost of deployment and maintenance. This is particularly important for organizations with limited resources or those that need to deploy language models on edge devices or in resource-constrained environments.\n",
      "5. **Real-Time Applications**: Fast language models are essential for real-time applications, such as:\n",
      "\t* Live captioning and subtitling\n",
      "\t* Real-time translation\n",
      "\t* Sentiment analysis and opinion mining\n",
      "\t* Chatbots and virtual assistants\n",
      "\t* Speech recognition and synthesis\n",
      "6. **Competitive Advantage**: Organizations that adopt fast language models can gain a competitive advantage in the market. For example, a company with a fast and accurate language model can provide better customer support, improve customer engagement, and enhance its overall brand reputation.\n",
      "7. **Research and Development**: Fast language models can accelerate research and development in various fields, such as:\n",
      "\t* Natural Language Processing (NLP)\n",
      "\t* Machine Learning (ML)\n",
      "\t* Artificial Intelligence (AI)\n",
      "\t* Human-Computer Interaction (HCI)\n",
      "8. **Edge AI and IoT**: Fast language models are critical for edge AI and IoT applications, where devices have limited computational resources and require efficient processing to function effectively.\n",
      "9. **Environmental Benefits**: By reducing the computational resources required for language processing, fast language models can help minimize the environmental impact of AI systems, such as energy consumption and e-waste generation.\n",
      "10. **Future-Proofing**: As language models continue to evolve and improve, fast language models will be better equipped to handle future demands and advancements in AI, ensuring that organizations and developers can stay ahead of the curve.\n",
      "\n",
      "In summary, fast language models are essential for a wide range of applications, from real-time processing and efficient deployment to competitive advantage and environmental benefits. As the demand for language processing continues to grow, the importance of fast language models will only continue to increase.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a30efe",
   "metadata": {},
   "source": [
    "### Classe Agent que encapsula a interação com o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ed2a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, client: Groq, system: str = \"\") -> None:\n",
    "        self.client = client # Cliente Groq\n",
    "        self.system = system # Prompt do sistema\n",
    "        self.messages: list = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "    # Método principal que processa mensagens e obtém respostas\n",
    "    def __call__(self, message=\"\"):\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute() # Chama o modelo\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "    # Executa a chamada à API do Groq\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama3-70b-8192\", messages=self.messages\n",
    "        )\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2104d40",
   "metadata": {},
   "source": [
    "### Prompt do sistema que define o comportamento do agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dc4f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "get_planet_mass:\n",
    "e.g. get_planet_mass: Earth\n",
    "returns weight of the planet in kg\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the mass of Earth times 2?\n",
    "Thought: I need to find the mass of Earth\n",
    "Action: get_planet_mass: Earth\n",
    "PAUSE \n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: 5.972e24\n",
    "\n",
    "Thought: I need to multiply this by 2\n",
    "Action: calculate: 5.972e24 * 2\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this: \n",
    "\n",
    "Observation: 1,1944×10e25\n",
    "\n",
    "If you have the answer, output it as the Answer.\n",
    "\n",
    "Answer: The mass of Earth times 2 is 1,1944×10e25.\n",
    "\n",
    "Now it's your turn:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3661e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23655f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(operation: str) -> float:\n",
    "    return eval(operation)\n",
    "\n",
    "\n",
    "def get_planet_mass(planet) -> float:\n",
    "    match planet.lower():\n",
    "        case \"earth\":\n",
    "            return 5.972e24\n",
    "        case \"jupiter\":\n",
    "            return 1.898e27\n",
    "        case \"mars\":\n",
    "            return 6.39e23\n",
    "        case \"mercury\":\n",
    "            return 3.285e23\n",
    "        case \"neptune\":\n",
    "            return 1.024e26\n",
    "        case \"saturn\":\n",
    "            return 5.683e26\n",
    "        case \"uranus\":\n",
    "            return 8.681e25\n",
    "        case \"venus\":\n",
    "            return 4.867e24\n",
    "        case _:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07831e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "neil_tyson = Agent(client=client, system=system_prompt)\n",
    "\n",
    "import re\n",
    "\n",
    "# Função principal que implementa o loop de interação com o agente\n",
    "\n",
    "def loop(max_iterations=10, query: str = \"\"):\n",
    "\n",
    "    agent = Agent(client=client, system=system_prompt)\n",
    "\n",
    "    tools = [\"calculate\", \"get_planet_mass\"] # Lista de ferramentas disponíveis\n",
    "\n",
    "    next_prompt = query\n",
    "\n",
    "    i = 0\n",
    "  \n",
    "    while i < max_iterations:\n",
    "        i += 1\n",
    "        result = agent(next_prompt)\n",
    "        print(result)\n",
    "\n",
    "        if \"PAUSE\" in result and \"Action\" in result:\n",
    "            action = re.findall(r\"Action: ([a-z_]+): (.+)\", result, re.IGNORECASE)\n",
    "            chosen_tool = action[0][0]\n",
    "            arg = action[0][1]\n",
    "\n",
    "            if chosen_tool in tools:\n",
    "                # Executa a ferramenta correspondente\n",
    "                result_tool = eval(f\"{chosen_tool}('{arg}')\")\n",
    "                next_prompt = f\"Observation: {result_tool}\"\n",
    "\n",
    "            else:\n",
    "                next_prompt = \"Observation: Tool not found\"\n",
    "\n",
    "            print(next_prompt)\n",
    "            continue\n",
    "\n",
    "        if \"Answer\" in result: # Se encontrou a resposta, termina\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6bada9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to find the mass of Earth and Saturn, then add them together and multiply by 2.\n",
      "Thought: I need to find the mass of Earth and Saturn \n",
      "\n",
      "Action: get_planet_mass: Earth\n",
      "PAUSE\n",
      "Observation: 5.972e+24\n",
      "Thought: Now I have the mass of Earth, I need to get the mass of Saturn \n",
      "\n",
      "Action: get_planet_mass: Saturn\n",
      "PAUSE\n",
      "Observation: 5.683e+26\n",
      "Thought: Now I have the masses of both planets, I need to add them together \n",
      "\n",
      "Action: calculate: 5.972e24 + 5.683e26\n",
      "PAUSE\n",
      "Observation: 5.74272e+26\n",
      "Thought: Now I have the sum of the masses, I need to multiply it by 2 \n",
      "\n",
      "Action: calculate: 5.74272e26 * 2\n",
      "PAUSE\n",
      "Observation: 1.148544e+27\n",
      "Thought: I have the final answer \n",
      "\n",
      "Answer: The mass of Earth plus the mass of Saturn and all of that times 2 is 1.148544e+27.\n"
     ]
    }
   ],
   "source": [
    "loop(query=\"What is the mass of Earth plus the mass of Saturn and all of that times 2?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
