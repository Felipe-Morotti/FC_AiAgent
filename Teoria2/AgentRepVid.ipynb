{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3acf3334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: groq in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (0.24.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (2.11.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from groq) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\felip\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be40165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GROQ_API_KEY'] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4bd89b",
   "metadata": {},
   "source": [
    "### Configuração inicial do cliente Groq para acessar a API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e1675b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial for various applications and industries, and their importance can be understood from several perspectives:\n",
      "\n",
      "1. **Efficient Processing**: Fast language models enable quick processing of large amounts of text data, which is essential for applications that require real-time or near-real-time responses, such as:\n",
      "\t* Chatbots and virtual assistants\n",
      "\t* Sentiment analysis and opinion mining\n",
      "\t* Text classification and categorization\n",
      "\t* Language translation and localization\n",
      "2. **Scalability**: Fast language models can handle massive volumes of data, making them ideal for large-scale applications, such as:\n",
      "\t* Social media monitoring and analysis\n",
      "\t* Customer service and support platforms\n",
      "\t* Content moderation and filtering\n",
      "\t* Data mining and business intelligence\n",
      "3. **Improved User Experience**: Fast language models can significantly enhance user experience by providing:\n",
      "\t* Rapid response times\n",
      "\t* Accurate and relevant results\n",
      "\t* Personalized recommendations and suggestions\n",
      "\t* Seamless language translation and communication\n",
      "4. **Competitive Advantage**: Organizations that leverage fast language models can gain a competitive edge by:\n",
      "\t* Responding quickly to customer inquiries and concerns\n",
      "\t* Analyzing and acting on market trends and sentiment\n",
      "\t* Developing innovative products and services\n",
      "\t* Enhancing their brand reputation and customer loyalty\n",
      "5. **Cost Savings**: Fast language models can help reduce costs by:\n",
      "\t* Automating manual tasks and processes\n",
      "\t* Minimizing the need for human intervention and review\n",
      "\t* Optimizing resource allocation and utilization\n",
      "\t* Reducing the time and effort required for data analysis and insights\n",
      "6. **Enhanced Security**: Fast language models can improve security by:\n",
      "\t* Detecting and responding to potential threats and vulnerabilities\n",
      "\t* Identifying and mitigating spam, phishing, and other malicious activities\n",
      "\t* Analyzing and filtering sensitive information and data\n",
      "\t* Enhancing authentication and authorization processes\n",
      "7. **Research and Development**: Fast language models can accelerate research and development in various fields, such as:\n",
      "\t* Natural Language Processing (NLP)\n",
      "\t* Artificial Intelligence (AI)\n",
      "\t* Machine Learning (ML)\n",
      "\t* Human-Computer Interaction (HCI)\n",
      "\n",
      "To achieve fast language models, researchers and developers employ various techniques, such as:\n",
      "\n",
      "1. **Model pruning and compression**\n",
      "2. **Knowledge distillation**\n",
      "3. **Quantization and approximation**\n",
      "4. **Parallelization and distributed computing**\n",
      "5. **Optimized algorithms and data structures**\n",
      "\n",
      "By developing and utilizing fast language models, organizations can unlock new opportunities, improve efficiency, and drive innovation in various industries and applications.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a30efe",
   "metadata": {},
   "source": [
    "### Classe Agent que encapsula a interação com o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ed2a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, client: Groq, system: str = \"\") -> None:\n",
    "        self.client = client # Cliente Groq\n",
    "        self.system = system # Prompt do sistema\n",
    "        self.messages: list = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "    # Método principal que processa mensagens e obtém respostas\n",
    "    def __call__(self, message=\"\"):\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute() # Chama o modelo\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "    # Executa a chamada à API do Groq\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama3-70b-8192\", messages=self.messages\n",
    "        )\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2104d40",
   "metadata": {},
   "source": [
    "### Prompt do sistema que define o comportamento do agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dc4f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "get_planet_mass:\n",
    "e.g. get_planet_mass: Earth\n",
    "returns weight of the planet in kg\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the mass of Earth times 2?\n",
    "Thought: I need to find the mass of Earth\n",
    "Action: get_planet_mass: Earth\n",
    "PAUSE \n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: 5.972e24\n",
    "\n",
    "Thought: I need to multiply this by 2\n",
    "Action: calculate: 5.972e24 * 2\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this: \n",
    "\n",
    "Observation: 1,1944×10e25\n",
    "\n",
    "If you have the answer, output it as the Answer.\n",
    "\n",
    "Answer: The mass of Earth times 2 is 1,1944×10e25.\n",
    "\n",
    "Now it's your turn:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7ff431",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23655f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(operation: str) -> float:\n",
    "    return eval(operation)\n",
    "\n",
    "\n",
    "def get_planet_mass(planet) -> float:\n",
    "    match planet.lower():\n",
    "        case \"earth\":\n",
    "            return 5.972e24\n",
    "        case \"jupiter\":\n",
    "            return 1.898e27\n",
    "        case \"mars\":\n",
    "            return 6.39e23\n",
    "        case \"mercury\":\n",
    "            return 3.285e23\n",
    "        case \"neptune\":\n",
    "            return 1.024e26\n",
    "        case \"saturn\":\n",
    "            return 5.683e26\n",
    "        case \"uranus\":\n",
    "            return 8.681e25\n",
    "        case \"venus\":\n",
    "            return 4.867e24\n",
    "        case _:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07831e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "neil_tyson = Agent(client=client, system=system_prompt)\n",
    "\n",
    "import re\n",
    "\n",
    "# Função principal que implementa o loop de interação com o agente\n",
    "\n",
    "def loop(max_iterations=10, query: str = \"\"):\n",
    "\n",
    "    agent = Agent(client=client, system=system_prompt)\n",
    "\n",
    "    tools = [\"calculate\", \"get_planet_mass\"] # Lista de ferramentas disponíveis\n",
    "\n",
    "    next_prompt = query\n",
    "\n",
    "    i = 0\n",
    "  \n",
    "    while i < max_iterations:\n",
    "        i += 1\n",
    "        result = agent(next_prompt)\n",
    "        print(result)\n",
    "\n",
    "        if \"PAUSE\" in result and \"Action\" in result:\n",
    "            action = re.findall(r\"Action: ([a-z_]+): (.+)\", result, re.IGNORECASE)\n",
    "            chosen_tool = action[0][0]\n",
    "            arg = action[0][1]\n",
    "\n",
    "            if chosen_tool in tools:\n",
    "                # Executa a ferramenta correspondente\n",
    "                result_tool = eval(f\"{chosen_tool}('{arg}')\")\n",
    "                next_prompt = f\"Observation: {result_tool}\"\n",
    "\n",
    "            else:\n",
    "                next_prompt = \"Observation: Tool not found\"\n",
    "\n",
    "            print(next_prompt)\n",
    "            continue\n",
    "\n",
    "        if \"Answer\" in result: # Se encontrou a resposta, termina\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6bada9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to find the mass of Earth and Saturn, then add them together, and finally multiply the result by 2.\n",
      "\n",
      "Action: get_planet_mass: Earth\n",
      "\n",
      "PAUSE\n",
      "Observation: 5.972e+24\n",
      "Thought: Now I have the mass of Earth, I need to find the mass of Saturn.\n",
      "\n",
      "Action: get_planet_mass: Saturn\n",
      "\n",
      "PAUSE\n",
      "Observation: 5.683e+26\n",
      "Thought: Now I have the masses of both planets, I need to add them together.\n",
      "\n",
      "Action: calculate: 5.972e+24 + 5.683e+26\n",
      "\n",
      "PAUSE\n",
      "Observation: 5.74272e+26\n",
      "Thought: Now I have the sum of the masses, I need to multiply it by 2.\n",
      "\n",
      "Action: calculate: 5.74272e+26 * 2\n",
      "\n",
      "PAUSE\n",
      "Observation: 1.148544e+27\n",
      "Thought: I have the final result, which is the mass of Earth plus the mass of Saturn and all of that times 2.\n",
      "\n",
      "Answer: The mass of Earth plus the mass of Saturn and all of that times 2 is 1.148544e+27.\n"
     ]
    }
   ],
   "source": [
    "loop(query=\"What is the mass of Earth plus the mass of Saturn and all of that times 2?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
